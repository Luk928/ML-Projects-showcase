{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, callbacks\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from os import listdir, makedirs\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop('targetValue')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(batch_size)\n",
    "    return ds\n",
    "\n",
    "def get_normalization_layer(name, dataset):\n",
    "    # Create a Normalization layer for our feature.\n",
    "    normalizer = preprocessing.Normalization()\n",
    "    # Prepare a Dataset that only yields our feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    # Learn the statistics of the data.\n",
    "    normalizer.adapt(feature_ds)\n",
    "    return normalizer\n",
    "\n",
    "def load_subsample_data(sample_array, subsample_array):\n",
    "    \"\"\"\n",
    "    %author ≈Åukasz Ozimek\n",
    "    Function to use arrays of sample numbers to load in data of subsample audio features.\n",
    "    \n",
    "    Parameter:\n",
    "    sample_array - array of sample numbers\n",
    "    subsample_array - array of subsample data\n",
    "    \n",
    "    Returns:\n",
    "    final_array - array of subsample data for selected samples\n",
    "    \"\"\"\n",
    "    final_array = np.zeros(shape=(int(len(sample_array)*5),len(subsample_array.columns)))\n",
    "    idx = 0\n",
    "    for i in sample_array:\n",
    "        num = i*5\n",
    "        for n in range(0,5):\n",
    "            final_array[idx]=subsample_array[num+n:num+n+1]\n",
    "            idx+=1\n",
    "    return final_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_model(path, save_path, save_name_start = 'train', iter_num = 5, epoch_num =20):\n",
    "    \"\"\"\n",
    "    Function that creates datasets out of csv files and normalizes them using Keras layer preprocessing. Then a model is \n",
    "    created     and trained multiple times. Then it's metrics are saved and their summary is printed in the console.\n",
    "    \n",
    "    Parameters:\n",
    "    path - filepath of the csv document with features\n",
    "    save_path - directory where model metrics will be saved\n",
    "    save_name_start - beginning of each saved file\n",
    "    iter_num - number of Kfold splits\n",
    "    epoch_num - number of epochs\n",
    "    neurons - number of neurons on first dense layer\n",
    "    \n",
    "    Returns:\n",
    "    df - Padnas DataFrame with best metrics from each cycle\n",
    "    summary - model summary\n",
    "    \"\"\"\n",
    "    try:\n",
    "        makedirs(save_path)\n",
    "    except:\n",
    "        pass\n",
    "    save_path = save_path+save_name_start\n",
    "    file = path\n",
    "    df = pd.read_csv(file)\n",
    "    df.drop('Unnamed: 0', axis=1, inplace = True)\n",
    "    base = list(range(0,int(len(df)/5))) #array of numbers equal to number of whole samples\n",
    "    \n",
    "    # Defining list to store best values\n",
    "    best_loss = []\n",
    "    best_acc = []\n",
    "    best_loss_val = []\n",
    "    best_acc_val = []\n",
    "    batch_size = 20\n",
    "    iterator = 0\n",
    "    kfold = KFold(n_splits=iter_num, shuffle=True)\n",
    "    \n",
    "    for train_base, val_base in kfold.split(base):\n",
    "        train = pd.DataFrame(load_subsample_data(train_base, df),columns=df.columns)\n",
    "        val = pd.DataFrame(load_subsample_data(val_base, df),columns=df.columns)\n",
    "        train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "        column_list = train.columns[0:-1]\n",
    "        all_inputs = []\n",
    "        encoded_features = []\n",
    "        count = 0\n",
    "        for header in column_list:\n",
    "            count += 1\n",
    "            print('Processed %d column out of %d' % (count, len(column_list)), end=\"\\r\", flush=True)\n",
    "            numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "            normalization_layer = get_normalization_layer(header, train_ds)\n",
    "            encoded_numeric_col = normalization_layer(numeric_col)\n",
    "            all_inputs.append(numeric_col)\n",
    "            encoded_features.append(encoded_numeric_col)\n",
    "\n",
    "        print(\"\")\n",
    "        # Build model\n",
    "        all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "        x = tf.keras.layers.Dense(128, activation=\"relu\")(all_features)\n",
    "        x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "        x = tf.keras.layers.Dropout(0.4)(x)\n",
    "        output = tf.keras.layers.Dense(1)(x)\n",
    "        val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "        iterator += 1\n",
    "        print('Training cycle %d out of %d' % (iterator, iter_num), end=\"\\r\", flush=True)\n",
    "        model = tf.keras.Model(all_inputs, output)\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                      metrics=[\"accuracy\"])\n",
    "        \n",
    "        # Callback to save best model\n",
    "        checkpoint_val_acc = callbacks.ModelCheckpoint(\n",
    "        'model_val_acc_'+str(iterator)+'.h5', monitor='val_accuracy', verbose=0, save_best_only=True,\n",
    "        save_weights_only=False,  save_freq='epoch' )\n",
    "        \n",
    "        model.fit(train_ds, epochs=epoch_num, validation_data=val_ds, verbose=0,callbacks=[checkpoint_val_acc])\n",
    "        df2 = pd.DataFrame()\n",
    "        for part in ['loss', 'accuracy', 'val_loss', 'val_accuracy']: \n",
    "            df2[part] = model.history.history[part]\n",
    "        df2.index.names = ['Epoch']\n",
    "        df2.to_csv(save_path+'_training'+str(iterator)+'.csv')\n",
    "        \n",
    "        # Save best values\n",
    "        best_loss.append(max(model.history.history['loss']))\n",
    "        best_acc.append(max(model.history.history['accuracy']))\n",
    "        best_loss_val.append(max(model.history.history['val_loss']))\n",
    "        best_acc_val.append(max(model.history.history['val_accuracy']))\n",
    "        print(\"\")\n",
    "    \n",
    "    # Post training\n",
    "    summary = model.summary # Every model is the same so the summary can be called post training loop\n",
    "    df = pd.DataFrame()\n",
    "    df['Best_Loss'] = best_loss\n",
    "    df['Best_Acc'] = best_acc\n",
    "    df['Best_Loss_Val'] = best_loss_val\n",
    "    df['Best_Acc_Val'] = best_acc_val\n",
    "    df.index.names = ['Model_Num']\n",
    "    df.to_csv(save_path+'_best'+'.csv')\n",
    "    return df, summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 88 column out of 88\n",
      "Training cycle 1 out of 8\n",
      "Processed 88 column out of 88\n",
      "Training cycle 2 out of 8\n",
      "Processed 88 column out of 88\n",
      "Training cycle 3 out of 8\n",
      "Processed 88 column out of 88\n",
      "Training cycle 4 out of 8\n",
      "Processed 88 column out of 88\n",
      "Training cycle 5 out of 8\n",
      "Processed 88 column out of 88\n",
      "Training cycle 6 out of 8\n",
      "Processed 88 column out of 88\n",
      "Training cycle 7 out of 8\n",
      "Processed 88 column out of 88\n",
      "Training cycle 8 out of 8\n"
     ]
    }
   ],
   "source": [
    "df, summary = data_model('./csvs/eGeMAPS/ReadText_eGeMAPSv01b.csv', './model_testing/ReadText_eGeMAPSv01b/',\n",
    "                         'Metrics', iter_num=8, epoch_num=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best_Loss</th>\n",
       "      <th>Best_Acc</th>\n",
       "      <th>Best_Loss_Val</th>\n",
       "      <th>Best_Acc_Val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_Num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.493167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.169979</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.980464</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.867504</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.057045</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>2.753671</td>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.829454</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>4.551526</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.818818</td>\n",
       "      <td>0.993750</td>\n",
       "      <td>7.454044</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.210269</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.800010</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.220295</td>\n",
       "      <td>0.993939</td>\n",
       "      <td>9.029058</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.835428</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.503509</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Best_Loss  Best_Acc  Best_Loss_Val  Best_Acc_Val\n",
       "Model_Num                                                  \n",
       "0           6.493167  1.000000       6.169979          0.92\n",
       "1           3.980464  1.000000       3.867504          0.80\n",
       "2           4.057045  0.993750       2.753671          0.96\n",
       "3           5.829454  0.993750       4.551526          1.00\n",
       "4           5.818818  0.993750       7.454044          0.80\n",
       "5           6.210269  1.000000       5.800010          0.85\n",
       "6           2.220295  0.993939       9.029058          0.65\n",
       "7           3.835428  1.000000       2.503509          0.85"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 88 column out of 88\n",
      "Training cycle 1 out of 5\n",
      "Processed 88 column out of 88\n",
      "Training cycle 2 out of 5\n",
      "Processed 88 column out of 88\n",
      "Training cycle 3 out of 5\n",
      "Processed 88 column out of 88\n",
      "Training cycle 4 out of 5\n",
      "Processed 88 column out of 88\n",
      "Training cycle 5 out of 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best_Loss</th>\n",
       "      <th>Best_Acc</th>\n",
       "      <th>Best_Loss_Val</th>\n",
       "      <th>Best_Acc_Val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model_Num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.500610</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.860439</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.799523</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.005357</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.878037</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.833271</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.320766</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.234532</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.726707</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.149543</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Best_Loss  Best_Acc  Best_Loss_Val  Best_Acc_Val\n",
       "Model_Num                                                  \n",
       "0           4.500610       1.0       1.860439           0.9\n",
       "1           5.799523       1.0       5.005357           1.0\n",
       "2           6.878037       1.0       6.833271           0.8\n",
       "3           5.320766       1.0      12.234532           0.6\n",
       "4           5.726707       1.0       9.149543           0.8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df, summary = data_model('./csvs/Whole files/WholeReadText_eGeMAPSv01b.csv', './whole/',\n",
    "                         'Metrics', iter_num=5, epoch_num=100)# There are 7 sapmles in a set, so number of splits must be smaller\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
